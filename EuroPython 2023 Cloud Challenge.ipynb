{"cells":[{"cell_type":"markdown","metadata":{"id":"7vEBNTHjuvon"},"source":["```text\n","SPDX-FileCopyrightText: 2023 Google LLC\n","SPDX-License-Identifier: Apache-2.0\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"yxKFLozC5tfO"},"source":["# EuroPython 2023 Cloud Challenge\n","\n","> **Warning**\n","> This Cloud Challenge took place during EuroPython 2023 and is now closed.\n","\n","## Build your Zen-erator with Vertex AI\n","\n","The **Zen of Python** provides very useful guiding principles:\n","\n","- Beautiful is better than ugly.\n","- Explicit is better than implicit.\n","- Simple is better than complex.\n","- Complex is better than complicated.\n","- Flat is better than nested.\n","- ‚Ä¶\n","\n","Let's generate your own \"Zen of\" using our latest Google Cloud LLM model, with the [Vertex AI PaLM API](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/generative-ai-studio)."]},{"cell_type":"markdown","metadata":{"id":"ZPcqv5S15t5A"},"source":["---\n","\n","## üíª Google Cloud\n","\n","- To complete this Cloud Challenge, you'll need a Google Cloud project.\n","- Redeem a 1 USD credit from [https://trygcp.dev/europython-2023](https://trygcp.dev/europython-2023), which will more than cover any potential cost.\n","- If you're already a Google Cloud user, create a new project and link it to the redeemed credit billing account.\n","- If you're new to Google Cloud,\n","  - This will get you started without a credit card.\n","  - Sign in with a Google account (your gmail account will do).\n","  - Follow the steps.\n","  - A \"My First Project\" will be created for you.\n","  - Copy your Project ID from the URL (`&project=YOUR-PROJECT-ID`)."]},{"cell_type":"markdown","metadata":{"id":"JAUW8f9oi8mi"},"source":["---\n","\n","## ‚úîÔ∏è Setup\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mn2UJ8_VUtFa"},"outputs":[],"source":["# @title üì¶Ô∏è Make sure you have the right packages (may restart) {display-mode: \"form\"}\n","\n","import sys\n","from importlib import metadata\n","\n","from IPython.core.getipython import get_ipython\n","from packaging import version\n","\n","# Services needed for this lab (with minimum version)\n","# Note: This assumes that earlier versions are non-breaking\n","GOOGLE_CLOUD_SERVICES = [\n","    (\"aiplatform\", \"1.25.0\"),\n","]\n","APIS = [f\"{service}.googleapis.com\" for service, _ in GOOGLE_CLOUD_SERVICES]\n","\n","# Check runtime\n","running_in_colab = \"google.colab\" in sys.modules\n","assert running_in_colab, \"‚ùå The notebook was only designed to run in Colab\"\n","print(\"‚úîÔ∏è Running in Colab\")\n","\n","# Check packages\n","packages = []\n","for service, min_version_str in GOOGLE_CLOUD_SERVICES:\n","    package = f\"google-cloud-{service}\"\n","    min_version = version.parse(min_version_str)\n","    try:\n","        lib = f\"google.cloud.{service}\"\n","        lib_version = version.parse(metadata.version(lib))\n","        if min_version <= lib_version:\n","            print(f\"‚úîÔ∏è {lib}=={lib_version!s}\")\n","            continue\n","        packages.append(package)\n","        print(f\"üì¶Ô∏è {package} to be updated‚Ä¶\")\n","    except metadata.PackageNotFoundError:\n","        packages.append(package)\n","        print(f\"üì¶Ô∏è {package} to be installed‚Ä¶\")\n","\n","if packages:\n","    # Install and restart\n","    requirements = \" \".join(packages)\n","    %pip install --upgrade $requirements --quiet\n","    if instance := get_ipython():\n","        instance.kernel.do_shutdown(True)\n","    raise RuntimeWarning(\"üîÑ Restarting‚Ä¶ (run the cell again)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Df7bSS-b7rdW"},"outputs":[],"source":["# @title ‚öôÔ∏è Enter your Google Cloud project ID {display-mode: \"form\"}\n","\n","PROJECT_ID = \"\"  # @param {type:\"string\"}\n","\n","assert PROJECT_ID, \"‚ùå Please enter your project ID\"\n","\n","print(f'‚úîÔ∏è PROJECT_ID: \"{PROJECT_ID}\"')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Xt81s9pOlfI"},"outputs":[],"source":["# @title üîë Authenticate (authorize your Google account to run this codelab) {display-mode: \"form\"}\n","from google.colab import auth\n","\n","auth.authenticate_user(project_id=PROJECT_ID)\n","print(f\"‚úîÔ∏è Authenticated\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w-QXa96aXzgw"},"outputs":[],"source":["# @title üîì Make sure the Vertex AI API is enabled {display-mode: \"form\"}\n","res = !gcloud services list --enabled --format \"value(config.name)\"\n","\n","apis_to_enable = \"\"\n","for api in APIS:\n","    if api in res:\n","        print(f'‚úîÔ∏è API \"{api}\" is enabled')\n","    else:\n","        apis_to_enable += f\"{api} \"\n","\n","if apis_to_enable:\n","    print(f'üîì Enabling API \"{apis_to_enable}\"‚Ä¶')\n","    !gcloud services enable $api\n","elif not APIS:\n","    print(f\"‚úîÔ∏è No specific API needed\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pgSgeHZsoJuf"},"outputs":[],"source":["# @title üõ†Ô∏è Define helper functions {display-mode: \"form\"}\n","\n","import base64\n","import json\n","\n","import pandas as pd\n","import requests\n","import vertexai\n","from IPython.display import display, display_markdown\n","from vertexai.language_models import TextGenerationModel, TextGenerationResponse\n","\n","\n","def predict(\n","    prompt: str,\n","    temperature: float = 0.5,\n","    max_output_tokens: int = 512,\n","    top_p: float = 0.8,\n","    top_k: int = 40,\n",") -> TextGenerationResponse:\n","    \"\"\"\n","    prompt: Question to ask the model\n","    temperature: Ratio [0..1] of randomness in token selection\n","    max_output_tokens: Max length of the output text in tokens\n","    top_p: Tokens are selected from most probable to least until the sum of their probabilities equals the top_p value\n","    top_k: Number of highest probability vocabulary tokens to keep for top-k-filtering\n","    \"\"\"\n","    LOCATION = \"us-central1\"\n","\n","    vertexai.init(project=PROJECT_ID, location=LOCATION)\n","    model = TextGenerationModel.from_pretrained(\"text-bison\")\n","    PARAMETERS = {\n","        \"temperature\": temperature,\n","        \"max_output_tokens\": max_output_tokens,\n","        \"top_p\": top_p,\n","        \"top_k\": top_k,\n","    }\n","\n","    return model.predict(prompt, **PARAMETERS)\n","\n","\n","def get_sentences(response: TextGenerationResponse) -> list[str]:\n","    try:\n","        sentences = json.loads(response.text)\n","        if isinstance(sentences, list):\n","            return sentences\n","        print(\"Error: Could not decode the answer as a string list.\")\n","    except json.JSONDecodeError:\n","        print(\n","            \"Error: Could not decode the answer as JSON. If the generated answer was too long/truncated, retry or increase the parameter max_output_tokens in the request.\"\n","        )\n","    return []\n","\n","\n","def emoji_digits_for_integer(i: int) -> str:\n","    emojis = \"\"\n","    while True:\n","        i, digit = divmod(i, 10)\n","        emoji = \"0Ô∏è‚É£1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£8Ô∏è‚É£9Ô∏è‚É£\"[3 * digit : 3 * (digit + 1)]\n","        emojis = f\"{emoji}{emojis}\"\n","        if i == 0:\n","            return emoji\n","\n","\n","def display_zenof(topic: str, sentences: list[str]):\n","    data = (\n","        (emoji_digits_for_integer(number), sentence)\n","        for number, sentence in enumerate(sentences, 1)\n","    )\n","    df = pd.DataFrame(data=data)\n","    styler = df.style.set_properties(subset=[1], **{\"text-align\": \"left\"})\n","    styler.hide(axis=0).hide(axis=1)\n","\n","    display_markdown(f'# Here\\'s your Zen of \"{topic}\"', raw=True)\n","    display(styler)\n","\n","\n","def register(\n","    status: str,\n","    name: str,\n","    badge_id: str,\n","    eligible: bool,\n","    topic: str,\n","    sentences: list[str],\n","):\n","    url = \"https://ep23.lolo.dev/cloud_challenge_register\"\n","    status = status.encode(\"utf-16\", \"surrogatepass\").decode(\"utf-16\")\n","    name = name.encode(\"utf-16\", \"surrogatepass\").decode(\"utf-16\")\n","    zenof = dict(topic=topic, sentences=sentences)\n","    zenof_b64 = base64.b64encode(json.dumps(zenof).encode()).decode()\n","    context_slist = !gcloud config list --format json\n","    context = json.loads(\"\".join(context_slist))\n","    context_b64 = base64.b64encode(json.dumps(context).encode()).decode()\n","    data = dict(\n","        status=status,\n","        name=name,\n","        badge_id=badge_id,\n","        eligible=eligible,\n","        zenof_b64=zenof_b64,\n","        context_b64=context_b64,\n","    )\n","\n","    response = requests.post(url, data)\n","    if response.status_code == 200:\n","        message = response.text\n","    else:\n","        message = f\"‚ùå {response.status_code}: {response.text}\"\n","    print(message)\n","\n","\n","print(f\"‚úîÔ∏è Defined helper functions\")"]},{"cell_type":"markdown","metadata":{"id":"YuhPWlD5M1Kp"},"source":["---\n","## üêç Build your Zen-erator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iENksztVlon4"},"outputs":[],"source":["# @title Enter your favorite topic for your \"Zen of\". {display-mode: \"form\"}\n","\n","TOPIC = \"\"  # @param {type:\"string\"}\n","\n","assert TOPIC, \"‚ùå Please enter your topic\"\n","\n","print(f'‚úîÔ∏è TOPIC: \"{TOPIC}\"')"]},{"cell_type":"markdown","metadata":{"id":"0XvY9wB5rhWg"},"source":["We have crafted a possible prompt for you."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"irlSpN5AYQx3"},"outputs":[],"source":["prompt = f\"\"\"\n","For the following topic, return 5 sentences as string list in JSON.\n","Each sentence must be a positive principle inspired by the Zen philosophy, as short as possible.\n","TOPIC: {TOPIC}\n","JSON:\n","\"\"\"\n","\n","print(f'Here is a possible prompt for your Zen-erator about \"{TOPIC}\":\\n‚Üì{prompt}‚Üë')"]},{"cell_type":"markdown","metadata":{"id":"T1Aly0Yurqvy"},"source":["This is the helper function we previously defined to call the PaLM API:\n","\n","```python\n","def predict(\n","    prompt: str,\n","    temperature: float = 0.5,\n","    max_output_tokens: int = 512,\n","    top_p: float = 0.8,\n","    top_k: int = 40,\n",") -> TextGenerationResponse:\n","    vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n","    model = TextGenerationModel.from_pretrained(\"text-bison\")\n","    PARAMETERS = {\n","        \"temperature\": temperature,\n","        \"max_output_tokens\": max_output_tokens,\n","        \"top_p\": top_p,\n","        \"top_k\": top_k,\n","    }\n","    return model.predict(prompt, **PARAMETERS)\n","```\n","\n","Call the PaLM API to generate your \"Zen of\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKysAffRWGnv"},"outputs":[],"source":["response = predict(prompt, temperature=0.6)\n","\n","sentences = get_sentences(response)\n","\n","display_zenof(TOPIC, sentences)"]},{"cell_type":"markdown","metadata":{"id":"ViQ0D8YNs4ek"},"source":["You can try a few times until you're happy with your generated \"Zen of\".\n","\n","> Notes:\n","> - If you want the model to be as creative as possible (introduce more randomness), set the temperature parameter to `1.0`.\n","> - You can also try to finetune and improve the prompt. Let us know if you manage to get better results with a different prompt."]},{"cell_type":"markdown","metadata":{"id":"7HSWZdpNpP3_"},"source":["---\n","\n","## üèÜ Register for the daily raffles\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9HwaMH8pcom"},"outputs":[],"source":["# @markdown Select (or enter) 1 emoji that represents your mood.\n","STATUS = \"üöÄ\"  # @param [\"üöÄ\",\"üëç\",\"ü•∞\",\"üéâ\",\"üî¥\",\"üü†\",\"üü°\",\"üü¢\",\"üîµ\"] {allow-input: true}\n","\n","# @markdown Enter your full name (as printed on your EuroPython badge).\n","NAME = \"Jane Doe\"  # @param {type:\"string\"}\n","\n","# @markdown Enter your badge ID (bottom-left corner of your badge).\n","BADGE_ID = \"#ABCDE-N\"  # @param {type:\"string\"}\n","\n","# @markdown Are you eligible to participate? (set to False if you're a Googler)\n","ELIGIBLE = True  # @param {type:\"boolean\"}\n","\n","register(STATUS, NAME, BADGE_ID, ELIGIBLE, TOPIC, sentences)"]},{"cell_type":"markdown","metadata":{"id":"FLfZpayKvQnZ"},"source":["If you get the message `üëç You're registered!`, then you're all set. You have a chance to win a prize during one of the 3 daily raffles."]},{"cell_type":"markdown","metadata":{"id":"dNqzg9ylC0G2"},"source":["---\n","\n","## üéâ Congratulations\n","\n","- ‚úîÔ∏è You built a Zen-erator powered by the Vertex AI PaLM API.\n","- ‚úîÔ∏è You registered for the daily raffles!\n","\n","Don't forget to come back to our booth Wednesday/Thursday/Friday for each daily raffle:\n","\n","- ‚è∞ See you at **15:15**\n","- ‚òï That's right in the **middle of the afternoon break**\n","\n","> If your name is drawn but you're not there, we'll have to relaunch the wheel to give the prize to another winner.\n","\n","Feel free to come to our booth anytime to chat about your \"Zen of\", Google Cloud, Python, or anything.\n","\n","We wish you the best EuroPython!"]}],"metadata":{"colab":{"provenance":[{"file_id":"1J8F3caMWm0JORsqOaF_esqj0-MGRWt3V","timestamp":1689715074036},{"file_id":"1M7CbrcMz9ZafXgbbjYCwzqCDHWJMqEGU","timestamp":1689163753149}]},"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
